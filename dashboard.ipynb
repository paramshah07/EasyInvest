{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab94f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from dotenv import find_dotenv\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from finquant.portfolio import build_portfolio\n",
    "\n",
    "import panel as pn\n",
    "pn.extension('plotly')\n",
    "import plotly.express as px\n",
    "import hvplot.pandas\n",
    "\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from IPython.display import IFrame\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "\n",
    "import functions\n",
    "f = functions.Functionalities('User Inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f00f03",
   "metadata": {},
   "source": [
    "## GRANDMA & GRANDPA'S ETF\n",
    "\n",
    "Capture user data and generate a risk profile. Match the risk profile to the best ETF from the API data derived with sharpe ratios and volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09071c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.startquiz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2c5d19",
   "metadata": {},
   "source": [
    "<img src=\"./images/userinput.gif\" alt=\"sunburst\" width=\"55%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9529d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying Results upon running this cell\n",
    "user_category = f.submitanswers()\n",
    "user_r = f.user_risk_tol()\n",
    "\n",
    "print(\"User Category Chosen: \" +user_category)\n",
    "print(\"User Risk Tolerance: \" +user_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select the ticker based on user inputs on category and risk \n",
    "def select_ticker(user_category, user_risk):\n",
    "    #pull ETF of choice based on above\n",
    "\n",
    "    etfs_path = Path(\"./Resources/map_data.csv\")\n",
    "    etf_df = pd.read_csv(etfs_path)\n",
    "    etf_df.index = [x for x in range(1, len(etf_df.values)+1)]\n",
    "    etf_df.head()\n",
    "    ## To Do Add logic based on inputs \n",
    "    selected = etf_df.loc[etf_df['Type'] == user_category]\n",
    "    \n",
    "    index = 1 # risk low = first one in sliced data as it is sorted by sharpe values \n",
    "    \n",
    "    if (user_risk==\"high\"):\n",
    "        index = selected['Ticker'].count()-1 # last row in the sliced data \n",
    "    \n",
    "    return selected.head(index)\n",
    "\n",
    "    #Pulling the ETF with suited risk\n",
    "\n",
    "    #final_etf = etf_df.loc[etf_df['Risk'] == user_r]\n",
    "\n",
    "    #Set ETF information as Variables (Might need to add here when final CSV is ready)\n",
    "    #Ticker = final_etf.loc[final_etf['Ticker']]\n",
    "    #Name = final_etf.loc[final_etf['Name']]\n",
    "    #Type = final_etf.loc[final_etf['Type']]\n",
    "    #Instrument = final_etf.loc[final_etf['Instrument']]\n",
    "    #Source = final_etf.loc[final_etf['Source']]\n",
    "    #Risk = final_etf.loc[final_etf['Risk']]\n",
    "\n",
    "selected = select_ticker(user_category,user_r)\n",
    "ticker = selected['Ticker'].values[0]\n",
    "#selected\n",
    "print (\"Selected Ticker\")\n",
    "print (ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcae7c9",
   "metadata": {},
   "source": [
    "## API data and plots for various analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad90612",
   "metadata": {},
   "source": [
    " - Take the ETF and pull out the data required\n",
    " - Create dataframes and data for visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500fa9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load .env enviroment variables\n",
    "load_dotenv(find_dotenv())\n",
    "################################## Retrieve API tokens Test ##########################\n",
    "map_box_api = \"pk.eyJ1IjoiYW5hbnRoaWdvayIsImEiOiJja3B3NzhubW0wYmg4MndwNTdybDluemJ4In0.WNzNIifbI23vuCcLMgFT2Q\"\n",
    "eod_api_token = \"OeAFFmMliFG5orCUuwAKQ8l4WWFQ67YX\" #\"60e415e799c1b9.28048629\"\n",
    "eod_api_t_token = \"OeAFFmMliFG5orCUuwAKQ8l4WWFQ67YX\"\n",
    "#google_geo_api_key = \"AIzaSyCZ3-rJbGsx3OJfQ5kIUmGu5YWioeCPDOM\"\n",
    "################################## Retrieve API tokens ##########################\n",
    "#   Set the Mapbox API Token/Key\n",
    "#map_box_api = os.getenv(\"MAPBOX_PUB_TOKEN\")\n",
    "px.set_mapbox_access_token(map_box_api)\n",
    "#\n",
    "#   EOD Key\n",
    "eod_api_token = os.getenv('EODHISTORICAL_API_KEY')\n",
    "eod_api_token = \"?api_token=\" + eod_api_token\n",
    "f.eod_api_token = eod_api_token\n",
    "#\n",
    "#   EOD Test Key\n",
    "#eod_api_t_token = os.getenv('EODHISTORICAL_API_KEY_TEST')\n",
    "eod_api_t_token = \"?api_token=\" + eod_api_t_token\n",
    "#f.eod_api_t_token = eod_api_t_token\n",
    "#\n",
    "#   Google Geo Key & URL\n",
    "google_geo_api_key = os.getenv('GOOGLE_GEO_API_KEY')\n",
    "google_geo_api_key = \"&key=\" + google_geo_api_key\n",
    "g_base_url = \"https://maps.googleapis.com/maps/api/geocode/json?address=\"\n",
    "\n",
    "#   Alpaca Key\n",
    "alpaca_api_key = os.getenv('ALPACA_API_KEY')\n",
    "alpaca_api_secret = os.getenv('ALPACA_SECRET_KEY')\n",
    "################################## Retrieve API tokens ##########################\n",
    "\n",
    "# The Ticker chosen ...\n",
    "#ticker = \"FTEC\"\n",
    "#ticker = \"VTI.US\"\n",
    "ticker = f.get_ticker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce409d2a",
   "metadata": {},
   "source": [
    "### Top10 ETF Constituents by Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotPieTop10Holdings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4605656b",
   "metadata": {},
   "source": [
    "### ETF Sector Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22099c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotPieSectorWeights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86998e72",
   "metadata": {},
   "source": [
    "### World Regional Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c5fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotWorldRegionalWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotBarReturnsPerPeriod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2742974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotEodDataForTop10Ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1e44f3",
   "metadata": {},
   "source": [
    "### Top10 Head Office Locations\n",
    "This visualisation shows the locations of each of the top 10 constituents by size.\n",
    "The size of the bubble shows the weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Fetch ETF data\n",
    "etf_t10_json = requests.get(f.eod_url(ticker,\"top10\",eod_api_token)).json()\n",
    "\n",
    "# Create list to populate dataframe\n",
    "etf_t10 = []\n",
    "etf_t10_ticks = []\n",
    "for i in etf_t10_json:\n",
    "    # Build ticker list\n",
    "    etf_t10_ticks.append([etf_t10_json[i]['Code']])\n",
    "\n",
    "    # Build DF data\n",
    "    etf_t10.append(\n",
    "        [etf_t10_json[i]['Code'],\n",
    "         etf_t10_json[i]['Assets_%']])\n",
    "\n",
    "# Create dataframe\n",
    "etf_t10_df = pd.DataFrame(etf_t10, columns=['Ticker','Top10 Weight']).set_index('Ticker')\n",
    "\n",
    "# Plot (Matplotlib)\n",
    "#etf_t10_df.plot.pie(subplots=True, figsize=(8,12), shadow=True)\n",
    "\n",
    "# Plotly\n",
    "etf_t10_df_ly = etf_t10_df.reset_index()\n",
    "\n",
    "####################\n",
    "def plotGeoMap():\n",
    "    ticker = f.get_ticker()\n",
    "    # Loop through the top10 tickers and for each,\n",
    "    # extract the address and use Google GEO API to\n",
    "    # find lat/lon ... and then use mapbox.\n",
    "\n",
    "    # Initialise lists for enriching DF\n",
    "    names = []\n",
    "    latts = []\n",
    "    longs = []\n",
    "    adds = []\n",
    "\n",
    "        # Loop through top10 tickers\n",
    "    #print(\"Extracting address for ...\")\n",
    "    for tick in etf_t10_ticks:\n",
    "        # Get and prepare the address\n",
    "        add_json = requests.get(f.eod_url(tick[0],\"none\",eod_api_token)).json()\n",
    "        names.append(add_json['General']['Name'])\n",
    "        add = add_json['General']['Address']\n",
    "        adds.append(add)   # For our viewing pleasure\n",
    "        geo_add = add.replace(' ','+') #^(\\s+)\n",
    "\n",
    "        # Get the Lat/Lon\n",
    "        g_geo_url = g_base_url + geo_add + google_geo_api_key\n",
    "        g_geo_json = requests.get(g_geo_url).json()\n",
    "        latts.append(g_geo_json['results'][0]['geometry']['location']['lat'])\n",
    "        longs.append(g_geo_json['results'][0]['geometry']['location']['lng'])\n",
    "\n",
    "    time.sleep(1) ## this takes some time to load data otherwise throws error\n",
    "    etf_t10_map_df = etf_t10_df.reset_index()\n",
    "\n",
    "    etf_t10_map_df['Name'] = names\n",
    "    etf_t10_map_df['Lattitude'] = latts\n",
    "    etf_t10_map_df['Longitude'] = longs\n",
    "    etf_t10_map_df['Address'] = adds\n",
    "\n",
    "    # Plot Mapbox scatter\n",
    "    tick_geo_map = px.scatter_mapbox(\n",
    "        etf_t10_map_df,\n",
    "        lat=\"Lattitude\",\n",
    "        lon=\"Longitude\",\n",
    "        size=\"Top10 Weight\",\n",
    "        title=\"HQs of Top10 Holdings\",\n",
    "        hover_data=[\"Ticker\",\"Top10 Weight\",\"Address\"],\n",
    "        color=\"Name\",\n",
    "        zoom=2.4,\n",
    "        height=500,\n",
    "        width=1050\n",
    "    )#.show()\n",
    "    return tick_geo_map\n",
    "\n",
    "#plotGeoMap()\n",
    "\n",
    "\n",
    "def plotETFvsConstituents():\n",
    "    ### Fetch end of day data for each Top10 Ticker and normalise the data\n",
    "#   Initialise vals\n",
    "    date = []\n",
    "    close = []\n",
    "    all_list = []\n",
    "    etf_t11_ticks = []\n",
    "    ind_counter = 0\n",
    "    counter = 0\n",
    "    col_names = {}\n",
    "    # Get ETF Inception Date\n",
    "    etf_start = requests.get(f.eod_url(ticker,\"start\",eod_api_token)).json()\n",
    "\n",
    "    #   Do some cleanup for all tickers\n",
    "    etf_t11_ticks.append(ticker)\n",
    "    for tick in etf_t10_ticks:\n",
    "        etf_t11_ticks.append(tick[0])\n",
    "\n",
    "    #   Initialise Alpaca URL and Auth Headers\n",
    "    alp_base_url = \"https://data.alpaca.markets/v2/stocks/\"\n",
    "    alp_filter = \"/bars?timeframe=1Day&end=2021-07-09&start=\" + etf_start\n",
    "    headers_dict = {\"APCA-API-KEY-ID\" : alpaca_api_key, \"APCA-API-SECRET-KEY\" : alpaca_api_secret}\n",
    "\n",
    "    # Loop through ETF + top10 tickers, build lists and DataFrame\n",
    "    #print(\"Extracting pricing data ...\")\n",
    "    for tick in etf_t11_ticks:\n",
    "        # Initialise for loop\n",
    "        date = []\n",
    "        close = []\n",
    "\n",
    "        # Pull back the JSON for each\n",
    "        alp_url = alp_base_url + tick + alp_filter\n",
    "        alp_json = requests.get(\n",
    "            alp_url,\n",
    "            headers = headers_dict\n",
    "        ).json()\n",
    "\n",
    "        # Build the lists for Dataframe\n",
    "        for ohlc in list(alp_json['bars']):\n",
    "            date.append(ohlc['t'])\n",
    "            close.append(ohlc['c'])\n",
    "\n",
    "        # Add date if all rows and first time\n",
    "        if len(date) == 1000 and ind_counter == 0:\n",
    "            col_names[counter] = \"date\"\n",
    "            all_list.append(date)\n",
    "            # Increment counts\n",
    "            ind_counter =+ 1\n",
    "            counter = counter+1\n",
    "\n",
    "        # Print progress\n",
    "        #print(f\"{tick}: {len(close)} days\")\n",
    "\n",
    "        # Add the closing prices to the list\n",
    "        all_list.append(close)\n",
    "        col_names[counter] = tick\n",
    "\n",
    "        # Increment count\n",
    "        counter = counter+1\n",
    "\n",
    "    # Populate dataframe\n",
    "    alp_data_df = pd.DataFrame({i:pd.Series(value) for i, value in enumerate(all_list)})\n",
    "    alp_data_df = alp_data_df.rename(columns=col_names).set_index('date')\n",
    "    #alp_data_df.head()\n",
    "\n",
    "    # Plot (Matplotlib)\n",
    "    #alp_data_df.plot(figsize=(14,9), title=\"Daily Prices - ETF vs Top10 Constituents\")\n",
    "\n",
    "    # Plotly\n",
    "    return px.line(alp_data_df, title=\"Daily Prices - ETF vs Top10 Constituents\", height=500, width=1000)#.show()\n",
    "\n",
    "#plotETFvsConstituents()\n",
    "\n",
    "#etf_names_json = requests.get(eod_url(ticker,\"gen\",eod_api_token)).json()\n",
    "#etf_names_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f543c887",
   "metadata": {},
   "source": [
    "## Panel Dashboard\n",
    "\n",
    "In this section, all of the plots are displayed into a single dashboard view using Panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e86318",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a Title for the Dashboard\n",
    "dash_title = \"# Grandpa Grandma ETF\"\n",
    "\n",
    "### Define a welcome text\n",
    "tab_welcome_msg =   \"Welcome to Grandpa Grandma ETF - Grandma and Grandpa's ETF was developed out of the concern that many older financially interested but technically challenged investors have, when trying to determine an appropriate investment vehicle to park their money.  The financial invesment world is full of earnest investment advice and latest investment crazes, which can generate confusion and trepidation. \"\n",
    "\n",
    "### Create a tab layout for the dashboard\n",
    "welcome_column = pn.Column(tab_welcome_msg, f.plotPieTop10Holdings())\n",
    "\n",
    "### Yearly Market Analysis, creating each plot with colours\n",
    "# then building the rows and column of rows\n",
    "#plot_eod_data_for_top10_ticker = plotEodDataForTop10Ticker()\n",
    "\n",
    "# plot for each column\n",
    "plot_world_regional_weights = f.plotWorldRegionalWeights()\n",
    "plot_pie_sector_weights = f.plotPieSectorWeights()\n",
    "plot_bar_returns_per_period = f.plotBarReturnsPerPeriod()\n",
    "plot_geo_map = plotGeoMap()\n",
    "plot_sunburts_ticker_analysis = f.sunburts_ticker_analysis()\n",
    "plot_ETF_vs_Constituents = plotETFvsConstituents()\n",
    "\n",
    "# Prep rows and column for the dashboard\n",
    "plot_world_regional_weights_r1 = pn.Row(plot_world_regional_weights)\n",
    "plot_world_regional_weights_r2 = pn.Row(plot_pie_sector_weights)\n",
    "plot_world_regional_weights_r1r2 = pn.Column(plot_world_regional_weights_r1,plot_world_regional_weights_r2)\n",
    "\n",
    "#plot_bar_returns_per_period_r1 = pn.Row(plot_bar_returns_per_period)\n",
    "plot_bar_returns_per_period_r1 = pn.Column(plot_bar_returns_per_period)\n",
    "\n",
    "#plot_geo_map_r1 = pn.Row(plot_geo_map)\n",
    "plot_geo_map_r1 = pn.Column(plot_geo_map)\n",
    "\n",
    "#sunburts_ticker_analysis_r1 = pn.Row(sunburts_ticker_analysis)\n",
    "sunburts_ticker_analysis_r1 = pn.Column(plot_sunburts_ticker_analysis)\n",
    "\n",
    "plot_ETF_vs_Constituents_r1 = pn.Column(plot_ETF_vs_Constituents)\n",
    "\n",
    "### Create the main dashboard\n",
    "dashboard = pn.Tabs(\n",
    "    (\"Welcome\", welcome_column),\n",
    "    (\"Holdings by Region and Sector\", plot_world_regional_weights_r1r2),\n",
    "    (\"HQs of Top 10 Holdings\",plot_geo_map_r1),\n",
    "    (\"ETF Returns Per Period\", plot_bar_returns_per_period_r1),\n",
    "    (\"Daily Prices - ETF vs Top10 Constituents\", plot_ETF_vs_Constituents_r1),\n",
    "    (\"Stock Prices\",sunburts_ticker_analysis_r1 )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dd1df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard.servable(dash_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a0e1f5",
   "metadata": {},
   "source": [
    "<img src=\"./images/dashboard_output_screenshot.png\" alt=\"sunburst\" width=\"55%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c58e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f37651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
